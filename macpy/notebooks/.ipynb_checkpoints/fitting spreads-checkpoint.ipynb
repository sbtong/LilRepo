{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import macpy\n",
    "import macpy.utils.database as db\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "#print plotly.__version__            # version 1.9.4 required\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot\n",
    "from plotly.graph_objs import Surface\n",
    "import cufflinks\n",
    "import plotly_layout as pl\n",
    "from plotly import tools\n",
    "\n",
    "import macpy.next_gen_curve as ngc\n",
    "import macpy.utils.ngc_utils as u\n",
    "import pandas as pd # isn't pandas already imported??\n",
    "\n",
    "#stuff for R2py library: calling R-functions through python\n",
    "import rpy2.robjects as robjects\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "plotly.offline.init_notebook_mode()\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:70% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calc_curve(df_both, alpha, tenor):\n",
    "    #alpha = level/change weighting coefficient\n",
    "    #tenor = choice of tenor\n",
    "    #df_both = merged dataframe of levels and changes for each tenor by TradeDate\n",
    "    tenor=str(tenor)\n",
    "    curve=[]\n",
    "    first_iteration=True\n",
    "    for i,r in df_both[[tenor + '_l', tenor + '_c']].iterrows(): \n",
    "        if first_iteration:\n",
    "            c=r[tenor + '_l']\n",
    "        else:\n",
    "            c=(1.-alpha)*r[tenor + '_l'] + alpha*(c_prev+ r[tenor + '_c'])  \n",
    "        #store results\n",
    "        tmp={}\n",
    "        tmp.update({'TradeDate':i, 'Curve':c})\n",
    "        curve.append(tmp)\n",
    "        #get ready for next iteration\n",
    "        c_prev = c\n",
    "        first_iteration=False\n",
    "    df_curve = pd.DataFrame(curve)\n",
    "    return df_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "use marketdata\n",
    "select distinct CurveName\n",
    "from researchcurves\n",
    "where Category like 'loglevel'\n",
    "and Lud > '2017-03-08'\n",
    "and Lud < '2017-03-10'\n",
    "\"\"\"\n",
    "df_names = db.MSSQL.extract_dataframe(sql, environment='DEV')\n",
    "names = np.array(df_names.CurveName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_names\n",
    "print ''\n",
    "print 'NUMBER of CURVES=' , len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curve_index=4\n",
    "specific_curve = str(names[curve_index])\n",
    "print specific_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "use marketdata\n",
    "select distinct TradeDate\n",
    "from researchcurves\n",
    "where CurveName = '%s'\n",
    "order by TradeDate\n",
    "\"\"\" % str(specific_curve)\n",
    "df_dates = db.MSSQL.extract_dataframe(sql, environment='DEV')\n",
    "dates = np.array(df_dates.TradeDate.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Start Date', dates[0]\n",
    "print 'End Date', dates[len(dates)-1]\n",
    "print 'NUMBER of DATES', len(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Curve History and Chart it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sql=\"\"\"\n",
    "use marketdata\n",
    "select CurveName, Category, TimeInYears, [Level], TradeDate from researchcurves\n",
    "where CurveName = '%s'\n",
    "and Category = 'loglevel'\n",
    "order by TradeDate, TimeInYears\n",
    "\"\"\" % (specific_curve)\n",
    "df_lvl = db.MSSQL.extract_dataframe(sql, environment='DEV')\n",
    "df_lvl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql=\"\"\"\n",
    "use marketdata\n",
    "select CurveName, Category, TimeInYears, [Level], TradeDate from researchcurves\n",
    "where CurveName = '%s'\n",
    "and Category = 'logchange'\n",
    "order by TradeDate, TimeInYears\n",
    "\"\"\" % (specific_curve)\n",
    "df_chng = db.MSSQL.extract_dataframe(sql, environment='DEV')\n",
    "df_chng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_lvlp = df_lvl.pivot('TradeDate','TimeInYears','Level')\n",
    "df_chngp = df_chng.pivot('TradeDate','TimeInYears','Level')\n",
    "cols = df_lvl.columns\n",
    "df_both = df_lvlp.merge(df_chngp, how='outer',left_index=True,right_index=True, suffixes=('_l', '_c')) ## outer join so we see which fail\n",
    "df_both.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see if there are any dates where only levels or changes were calculated\n",
    "tmp=df_both.isnull().any(axis=1)\n",
    "tmp.loc[tmp.values == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha=0.9\n",
    "tenor=20.0\n",
    "df_curve_lvl = calc_curve(df_both, 0.,tenor)\n",
    "df_curve_chng = calc_curve(df_both, 1.,tenor)\n",
    "df_curve = calc_curve(df_both, alpha,tenor)\n",
    "\n",
    "layout=pl.PlotLayout1('Date','Spread',width=900,title='%s: curve History Tenor=%sy, alpha=%s' % (specific_curve, tenor,alpha))\n",
    "trace2 = go.Scatter(x=df_curve.TradeDate,y=u.mExp(np.array(df_curve.Curve)),name='alpha = %s' % alpha, mode='lines')\n",
    "trace3 = go.Scatter(x=df_curve_lvl.TradeDate,y=u.mExp(np.array(df_curve_lvl.Curve)),name='Levels',mode='lines',line={'dash':'dot'})\n",
    "trace4 = go.Scatter(x=df_curve_chng.TradeDate,y=u.mExp(np.array(df_curve_chng.Curve)),name='Changes', mode='lines', line={'dash':'dash'})\n",
    "\n",
    "data=[trace2,trace3,trace4]\n",
    "\n",
    "plotly.offline.iplot({'data':data,'layout':layout})\n",
    "py.sign_in('Axioma01', 'qDOgcN9vocMJRGXbPbGG')\n",
    "filename = 'C:\\\\Users\\\\dantonio\\\\Documents\\\\Projects\\\\NextGenFit\\\\USD_TEN_SEN_20.pdf'\n",
    "fig = go.Figure(data=data,layout=layout)\n",
    "py.image.save_as(fig, filename=filename,format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha=0.9\n",
    "tenor=30.0\n",
    "df_curve_1 = calc_curve(df_both, alpha,1.0)\n",
    "df_curve_2 = calc_curve(df_both, alpha,2.0)\n",
    "df_curve_5 = calc_curve(df_both, alpha,5.0)\n",
    "df_curve_10 = calc_curve(df_both, alpha,10.0)\n",
    "df_curve_20 = calc_curve(df_both, alpha,20.0)\n",
    "df_curve_30 = calc_curve(df_both, alpha,30.0)\n",
    "\n",
    "layout=pl.PlotLayout1('Date','Spread',width=900,title='Curve History, alpha=%s' % (alpha))\n",
    "t1 = go.Scatter(x=df_curve_1.TradeDate,y=u.mExp(np.array(df_curve_1.Curve)),name='1y', mode='lines')\n",
    "t2 = go.Scatter(x=df_curve_2.TradeDate,y=u.mExp(np.array(df_curve_2.Curve)),name='2y', mode='lines')\n",
    "t3 = go.Scatter(x=df_curve_5.TradeDate,y=u.mExp(np.array(df_curve_5.Curve)),name='5y', mode='lines')\n",
    "t4 = go.Scatter(x=df_curve_10.TradeDate,y=u.mExp(np.array(df_curve_10.Curve)),name='10y', mode='lines')\n",
    "t5 = go.Scatter(x=df_curve_20.TradeDate,y=u.mExp(np.array(df_curve_20.Curve)),name='20y', mode='lines')\n",
    "t6 = go.Scatter(x=df_curve_30.TradeDate,y=u.mExp(np.array(df_curve_30.Curve)),name='30y', mode='lines')\n",
    "\n",
    "data=[t1, t2, t3, t4, t5, t6]\n",
    "\n",
    "plotly.offline.iplot({'data':data,'layout':layout})\n",
    "py.sign_in('Axioma01', 'qDOgcN9vocMJRGXbPbGG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fit on particular date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date = '2016-03-31'\n",
    "date_index = df_dates.loc[df_dates.TradeDate == date].index[0]\n",
    "start_date = dates[date_index-1]\n",
    "end_date = dates[date_index]\n",
    "Ticker = ''\n",
    "Currency = 'USD'\n",
    "category=''\n",
    "#specific_curve = Currency + '-' + Ticker + '-SEN'\n",
    "\n",
    "\n",
    "print start_date, ',', end_date, ', ', specific_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " specific_curve = 'JPY-TERUMO-SEN'\n",
    "\n",
    "xmlFileName = 'C:\\ContentDev-MAC\\macpy\\utils\\\\xml_test.xml'\n",
    "xml_params = u.parse_xml(xmlFileName,specific_curve)\n",
    "\n",
    "#xml params very useful for running all curves, but for ad hoc testing still useful to have direct input here:\n",
    "input_params = {'specific_curve': specific_curve,\n",
    "                'start_date': '2017-02-16',\n",
    "                'end_date': '2017-02-17',\n",
    "                'Currency': 'JPY',\n",
    "                'alpha':0.5,\n",
    "                'gamma':0.5,\n",
    "                'smfitCompressionShort':0.1,\n",
    "                'smfitCompressionLong':0.1,\n",
    "                'sigmaScaleLevels':0.2,\n",
    "                'sigmaScaleChanges':0.2,\n",
    "                'smfitSpldf':4,\n",
    "                'write_data':False,\n",
    "                'debugplot':True,\n",
    "                'debugplotSmoothFit':False,\n",
    "                'debugplot_ixlist':[-1],\n",
    "               'plot_f':False,\n",
    "               'sswidthLong':.05,\n",
    "               'sswidthShort':0.8,\n",
    "                'maxIter':10,\n",
    "                'numOutlierIterations': 3,\n",
    "                'numIterLevelGuess': 2,\n",
    "                'numBondsLevels':200,\n",
    "                'numBondsChanges': 200,\n",
    "                'overwriteStart':False}\n",
    "\n",
    "params={}\n",
    "params.update(xml_params)\n",
    "params.update(input_params)\n",
    "\n",
    "ssc_i = ngc.SmoothSplineCurve(**params)\n",
    "ssc_i.run_single()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Misc testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.nonparametric.api import KDEUnivariate\n",
    "def kde(x, x_grid, weights=None, bandwidth='normal_reference', kernel='gau', **kwargs):\n",
    "    \"\"\"Kernel Density Estimation with KDEUnivariate from statsmodels. **kwargs are the named arguments of KDEUnivariate.fit() \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    density = KDEUnivariate(x)\n",
    "    if (weights is not None):      # NOTE that KDEUnivariate.fit() cannot perform Fast Fourier Transform with non-zero weights\n",
    "        weights = np.asarray(weights)\n",
    "        weights / np.sum(weights)\n",
    "        neff = 1.0 / np.sum(weights ** 2)\n",
    "        print neff\n",
    "        d = 1.\n",
    "        \n",
    "        bw = np.power(neff, -1./(d+4.))  #scott\n",
    "        print 'bw', bw\n",
    "        \n",
    "        print 'sum', np.sum(weights)\n",
    "        if (len(x) == 1): # NOTE that KDEUnivariate.fit() cannot cope with one-dimensional weight array\n",
    "            density.fit(kernel=kernel, weights=None, fft=False, **kwargs)\n",
    "        else:\n",
    "            print 'here'\n",
    "            print x\n",
    "            print weights\n",
    "            density.fit(kernel='gau', weights=weights, bw=bw, fft=False, **kwargs)\n",
    "    else:\n",
    "        density.fit(kernel=kernel, **kwargs) #when kernel='gau' fft=true\n",
    "    return density.evaluate(x_grid), weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df.x\n",
    "w = df.w\n",
    "x_grid = np.arange(-1.,1.,0.05)\n",
    "test, weights = kde(x, x_grid, weights=w) #bandwidth automatically selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(test).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
